{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import needed libraries\n",
    "\n",
    "One of the reasons Python is so popular is because of its rich and comprehensive set of _third party libraries_ that focus on certain functionality that developers need.\n",
    "\n",
    "Some common libraries - and the associated purpose for each - are listed below: \n",
    "- [`pandas`](https://pandas.pydata.org/pandas-docs/stable/): Provides common data analysis tools and data structures - especially [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)s.\n",
    "- [`requests`](https://requests.readthedocs.io/en/master/): Whenever you need to make an API request to GET or POST data programmatically from a source like [Colorado Information Marketplace](https://data.colorado.gov/) or the [NREL API](https://developer.nrel.gov/), requests allows you easily make these API calls \n",
    "- [`numpy`](https://numpy.org/): Library focused on scientific computing, as well as performing operations common to various data structures\n",
    "- [`scipy`](https://www.scipy.org/): Similar to numpy in that the library focuses on scientific computing, `scipy` is more focused on complex mathematical/scientific operations. \n",
    "- [`matplotlib`](https://matplotlib.org/): Plotting library focused on data visualization\n",
    "\n",
    "These are just a few of the 200,000+ libraries available within the [Python ecosystem](https://pypi.org/).\n",
    "\n",
    "Below is the syntax to import these third-party libraries. Note that these imports will not work unless you have previously installed them from the `Pipenv` file using the command `pipenv install` from your terminal. (<< that's kinda jargony so let me know if this needs to be clarified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import git\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find appropriate path that includes our data set\n",
    "\n",
    "To structure this project, I decided to create a folder called `data` which includes all the CSVs needed for this tutorial.\n",
    "\n",
    "We'll be working with the file `Alternative_Energy_Laws_and_Incentives_in_Colorado_2014.csv`, downloaded from the Colorado Information Marketplace (CIM) [here](https://data.colorado.gov/Energy/Alternative-Energy-Laws-and-Incentives-in-Colorado/nxw4-ev8w). According to this site, this CSV includes data on:\n",
    "\n",
    "> _Law titles, text and dates for biofuels, natural gas, plug in electric and more categories from National Renewable Energy Laboratory (NREL) since 2007 and updated annually after each stateâ€™s legislative session ends_\n",
    "\n",
    "The library [`GitPython`](https://gitpython.readthedocs.io/en/stable/) - imported above with the syntax `import git` and used below through the code snippet `git.Repo()` - is a library used to interact git repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_NAME = 'data'\n",
    "GIT_ROOT_PATH = git.Repo(os.getcwd(), search_parent_directories=True).working_dir\n",
    "data_dir_full_path = os.path.join(GIT_ROOT_PATH, DATA_DIR_NAME)\n",
    "\n",
    "print(\"The data we'll be working with is in this directory:\\n{}\".format(\n",
    "    data_dir_full_path\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all files in data_dir_full_path\n",
    "files = os.listdir(data_dir_full_path)\n",
    "\n",
    "# list comprehension, extremely common and useful way to iterate through an array/list\n",
    "files_csv = [i for i in files if i.endswith('.csv')]\n",
    "# the above line goes through each file in the data directory, creating an array of filenames ending in .csv\n",
    "\n",
    "# takes the first (and only) .csv file from the files_csv array. Joins with data directory to get full path\n",
    "co_energy_laws_csv_path = os.path.join(data_dir_full_path, 'Alternative_Energy_Laws_and_Incentives_in_Colorado_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv from the path defined above. \n",
    "# `lawid` is the unique identifier of the data set we're working with, so we can set it as index_col\n",
    "co_energy_laws_df = pd.read_csv(co_energy_laws_csv_path, index_col = 'lawid')\n",
    "\n",
    "# show the first few rows in the dataset\n",
    "co_energy_laws_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"columns in dataset:\\n{}\".format(list(co_energy_laws_df.columns)))\n",
    "\n",
    "print(\"\\nnum rows in dataset: {}\\n\".format(co_energy_laws_df.shape[0]))\n",
    "\n",
    "print(\"Unique types of legislation: {}\\n\".format(\n",
    "    co_energy_laws_df.type.unique()) # alternate syntax, same result: co_energy_laws_df['type'].unique() \n",
    ")\n",
    "\n",
    "# iterate through the first 5 rows of the data set, and access the values of each row\n",
    "for idx, law in co_energy_laws_df[0:5].iterrows():\n",
    "    print(\"----------------\")\n",
    "    print(\"Legislation Name (Law ID {}): {}\".format(idx, law['title']))\n",
    "    print(\"----------------\")\n",
    "    print(law['text'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts() groups the given column name, and provides the number of rows for each value in the column\n",
    "co_energy_laws_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that this is a pipe-delimited column\n",
    "co_energy_laws_df['technologycategories'].value_counts()\n",
    "\n",
    "#the format of this column isn't conducive to analysis \n",
    "#bc there are multiple pieces of information in the column.\n",
    "\n",
    "#For example, the rows with `ELEC|HEV` represent legislation \n",
    "#encouraging two technologies - electric vehicles *and* hybrids.\n",
    "\n",
    "#We'll need to manipulate/transform these columns into\n",
    "#something more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all values of the technologycategories column\n",
    "tech_cats_array = co_energy_laws_df['technologycategories'].values\n",
    "\n",
    "# concat all of these values together with | \n",
    "tech_cats_concat = \"|\".join(tech_cats_array)\n",
    "\n",
    "print(\"all values concatenated together\\n: {}\\n\".format(tech_cats_concat))\n",
    "\n",
    "unique_tech_cats = list(set(tech_cats_concat.split(\"|\")))\n",
    "print(\"unique technologies:\\n{}\".format(unique_tech_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we'll create one column per technology.\n",
    "# this column will be a \"boolean\" (values are only True or False)\n",
    "\n",
    "for tech_cat in unique_tech_cats:\n",
    "    \n",
    "    co_energy_laws_df[\"tech_{}_flg\".format(tech_cat)] = \\\n",
    "        co_energy_laws_df.apply(lambda row: \n",
    "        True if tech_cat in row['technologycategories'] else False\n",
    "    , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co_energy_laws_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to check the transformation we ran on the data set (adding columns),\n",
    "# let's look at a few of the columns we created\n",
    "co_energy_laws_df[['technologycategories', 'tech_ELEC_flg', 'tech_BIOD_flg']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because there are multiple columns that have pipe-delimited values,\n",
    "# we can generalize the code created for `technologycategories` above \n",
    "# to create a function that we can call for the other columns\n",
    "\n",
    "def create_boolean_cols(df, col_name, new_col_name_prepend, sep = \"|\"):\n",
    "    \n",
    "    orig_col_vals_array = df[col_name].values\n",
    "    orig_col_vals_array = [x for x in orig_col_vals_array if x == x]\n",
    "    df[col_name] = df[col_name].astype(str)\n",
    "    \n",
    "    cats_concat = sep.join(orig_col_vals_array)\n",
    "    unique_cats = list(set(cats_concat.split(sep)))\n",
    "    \n",
    "    print(\"\\n-------------- start column name: {}\".format(col_name))\n",
    "    print(\"unique values:\\n{}\".format(unique_cats))\n",
    "    \n",
    "    col_prepend = \"{}_\".format(new_col_name_prepend)\n",
    "    \n",
    "    print(\"building out new boolean columns...\")\n",
    "    for cat in unique_cats:\n",
    "    \n",
    "        df[\"{col_prepend}{cat}_flg\".format(**locals())] = \\\n",
    "            df.apply(lambda row: \n",
    "            True if cat in row[col_name] else False\n",
    "        , axis=1)\n",
    "        \n",
    "    print(\"-------------- end column name: {}\".format(col_name))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_co_energy_laws_df = create_boolean_cols(\n",
    "    co_energy_laws_df, \n",
    "    \"incentivecategories\", #col_name\n",
    "    \"incentive\"\n",
    ")\n",
    "\n",
    "augmented_co_energy_laws_df = create_boolean_cols(\n",
    "    co_energy_laws_df, \n",
    "    \"regulationcategories\", #col_name\n",
    "    \"reg\"\n",
    ")\n",
    "\n",
    "augmented_co_energy_laws_df = create_boolean_cols(\n",
    "    co_energy_laws_df, \n",
    "    \"usercategories\", #col_name\n",
    "    \"user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_co_energy_laws_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_co_energy_laws_df[[\"usercategories\", \"user_FLEET_flg\", \"user_AFS_flg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
